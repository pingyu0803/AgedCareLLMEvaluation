# -*- coding: utf-8 -*-
"""Untitled84.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n4e8Bgz6zWffz7k4C0rIZ7mpauoSQCi9
"""

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.huggingface import HuggingFaceLLM
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import pandas as pd  # For CSV handling

# --- 1. Load Documents ---
documents = SimpleDirectoryReader("./RAGKnowledgeFiles").load_data()  # Your documents folder

# --- 2. Setup Embedding Model ---
embed_model = HuggingFaceEmbedding(
    model_name=""  # Embedding model
)

# --- 3. Load Local LLM ---
model_id = ""  # Small efficient model
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id)

llm_pipeline = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=512,
    temperature=0.3
)
llm = HuggingFaceLLM(pipeline=llm_pipeline)

# --- 4. Setup Service Context ---
service_context = ServiceContext.from_defaults(
    llm=llm,
    embed_model=embed_model,
    chunk_size=500,  # Better for small models
    chunk_overlap=50
)

# --- 5. Build Vector Index ---
index = VectorStoreIndex.from_documents(
    documents,
    service_context=service_context
)

# --- 6. Load Prompt & Test Data ---
with open("prompt.txt", "r") as f:
    prompt_template = f.read().strip()

# Load test data from CSV
test_data = pd.read_csv("test_data.csv")  # Assuming CSV has 'question' column
test_questions = test_data['question'].tolist()

# --- 7. Query Engine ---
query_engine = index.as_query_engine(
    similarity_top_k=3,  # Retrieve top 3 chunks
    streaming=False
)

# --- 8. Run Queries ---
for question in test_questions:
    # Combine prompt template with question
    full_query = f"{prompt_template}\n\nQuestion: {question}"

    # Get response
    response = query_engine.query(full_query)
    print("Answer:", str(response))